WEBVTT
Kind: captions
Language: en

00:00:00.380 --> 00:00:03.719
Thanks Dean. Throughout this lesson and others, Dean will give us more

00:00:03.719 --> 00:00:07.850
advice and discuss the big picture when doing EDA. For now, let's

00:00:07.850 --> 00:00:10.700
start by loading up some data. You can find a data file

00:00:10.700 --> 00:00:14.030
in the instructor notes. This data file contains all the Facebook data

00:00:14.030 --> 00:00:16.920
that we're going to be looking at. To load up the data, let's

00:00:16.920 --> 00:00:19.526
first make sure that we're in the right directory. Here is my

00:00:19.526 --> 00:00:21.970
current directory and I can see that I'm in a folder that

00:00:21.970 --> 00:00:25.410
has the data sets. I can use the list.files command to figure

00:00:25.410 --> 00:00:28.640
out what that files are within this directory and here is

00:00:28.640 --> 00:00:32.600
the data set that I want. The pseudo_facebook data set. To read

00:00:32.600 --> 00:00:36.110
in the data set I'm going to use the read.csv command. But

00:00:36.110 --> 00:00:38.260
I need to be a little bit careful. I need to indicate

00:00:38.260 --> 00:00:41.280
that the separator is really a tab. And that's because we're

00:00:41.280 --> 00:00:44.960
working with a tab separated values file. Running the command, I can

00:00:44.960 --> 00:00:47.840
see that I get my data set up in R. Now this

00:00:47.840 --> 00:00:50.530
data set is similar to the kind that data scientists see from

00:00:50.530 --> 00:00:52.900
time to time at Facebook. And it's especially the type

00:00:52.900 --> 00:00:55.800
of data that they'll use when doing EDA. This file

00:00:55.800 --> 00:01:00.070
has approximately 99,000 rows or observations in it with 15

00:01:00.070 --> 00:01:04.030
variables. Each observation represents a user and that user will

00:01:04.030 --> 00:01:06.660
have different information such as their age, their name or

00:01:06.660 --> 00:01:09.042
their date of birth. We can see all these variables

00:01:09.042 --> 00:01:12.760
by running the names command. Now in this entire process

00:01:12.760 --> 00:01:17.268
our goal is to understand our user's behavior and their demographics.

00:01:17.268 --> 00:01:19.840
We're going to want to understand what they're doing on Facebook

00:01:19.840 --> 00:01:22.330
and what they use. This is why you see things

00:01:22.330 --> 00:01:27.750
like friend_count, www_likes and mobile_likes. We created this data

00:01:27.750 --> 00:01:30.850
set specifically for this course to have many features common

00:01:30.850 --> 00:01:34.305
to such user level behavioral and demographic data. But

00:01:34.305 --> 00:01:36.615
I need to say that this data isn't actual Facebook

00:01:36.615 --> 00:01:39.770
data. So not all statistics in this data set

00:01:39.770 --> 00:01:42.610
are going to be accurate representations of how people use Facebook

00:01:42.610 --> 00:01:45.310
on a day to day basis. So our lawyers want me

00:01:45.310 --> 00:01:48.460
to make the disclaimer that this isn't actual data from Facebook

00:01:48.460 --> 00:01:51.480
users. But we did use a complex model to generate it,

00:01:51.480 --> 00:01:53.670
and I think we can learn some very interesting things about it.

